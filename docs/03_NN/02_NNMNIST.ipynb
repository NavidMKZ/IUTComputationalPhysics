{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5927d27d",
   "metadata": {},
   "source": [
    "# پیاده سازی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "یک ماژول برای پیاده‌سازی الگوریتم یادگیری گرادیان کاهش تصادفی برای یک شبکه عصبی پیش‌خور.\n",
    "گرادیان‌ها با استفاده از روش انتشار معکوس محاسبه می‌شوند.\n",
    "\"\"\"\n",
    "\n",
    "# کتابخانه‌های استاندارد\n",
    "import random\n",
    "\n",
    "# کتابخانه‌های شخص ثالث\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "    \"\"\"کلاس شبکه عصبی\"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"مقداردهی اولیه شبکه عصبی\n",
    "        \n",
    "        پارامترها:\n",
    "        sizes -- لیستی که تعداد نورون‌های هر لایه را مشخص می‌کند.\n",
    "                مثال: [2, 3, 1] برای شبکه‌ای با 2 نورون ورودی،\n",
    "                3 نورون در لایه پنهان و 1 نورون در لایه خروجی\n",
    "        \"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        # مقداردهی تصادفی بایاس‌ها با توزیع نرمال\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        # مقداردهی تصادفی وزن‌ها با توزیع نرمال\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"محاسبه خروجی شبکه برای ورودی داده شده\n",
    "        \n",
    "        پارامترها:\n",
    "        a -- ورودی شبکه\n",
    "        \n",
    "        برگشت:\n",
    "        خروجی شبکه\n",
    "        \"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "            \n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"آموزش شبکه با گرادیان کاهش تصادفی روی دسته‌های کوچک\n",
    "        \n",
    "        پارامترها:\n",
    "        training_data -- لیست داده‌های آموزشی به صورت (ورودی, خروجی مطلوب)\n",
    "        epochs -- تعداد دوره‌های آموزشی\n",
    "        mini_batch_size -- اندازه هر دسته کوچک\n",
    "        eta -- نرخ یادگیری\n",
    "        test_data -- داده‌های آزمون (اختیاری)\n",
    "        \"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            # ایجاد دسته‌های کوچک\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            # آموزش روی هر دسته کوچک\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            # نمایش پیشرفت آموزش\n",
    "            if test_data:\n",
    "                print(\"دوره {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print(\"دوره {0} تکمیل شد\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"به‌روزرسانی وزن‌ها و بایاس‌ها برای یک دسته کوچک\n",
    "        \n",
    "        پارامترها:\n",
    "        mini_batch -- یک دسته کوچک از داده‌های آموزشی\n",
    "        eta -- نرخ یادگیری\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            # محاسبه گرادیان‌ها با انتشار معکوس\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        # به‌روزرسانی وزن‌ها و بایاس‌ها\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"الگوریتم انتشار معکوس برای محاسبه گرادیان‌ها\n",
    "        \n",
    "        پارامترها:\n",
    "        x -- ورودی آموزشی\n",
    "        y -- خروجی مطلوب\n",
    "        \n",
    "        برگشت:\n",
    "        یک تاپل (nabla_b, nabla_w) که گرادیان‌های تابع هزینه را نشان می‌دهد\n",
    "        \"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # مرحله پیش‌خور\n",
    "        activation = x\n",
    "        activations = [x]  # ذخیره فعال‌سازی‌های هر لایه\n",
    "        zs = []  # ذخیره ورودی‌های هر لایه قبل از اعمال تابع فعال‌سازی\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # مرحله پس‌خور\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # محاسبه گرادیان‌ها برای لایه‌های قبلی\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"ارزیابی عملکرد شبکه روی داده آزمون\n",
    "        \n",
    "        پارامترها:\n",
    "        test_data -- داده‌های آزمون\n",
    "        \n",
    "        برگشت:\n",
    "        تعداد پیش‌بینی‌های صحیح\n",
    "        \"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"محاسبه مشتق تابع هزینه\n",
    "        \n",
    "        پارامترها:\n",
    "        output_activations -- فعال‌سازی‌های لایه خروجی\n",
    "        y -- خروجی مطلوب\n",
    "        \n",
    "        برگشت:\n",
    "        مشتق تابع هزینه نسبت به فعال‌سازی‌های خروجی\n",
    "        \"\"\"\n",
    "        return (output_activations-y)\n",
    "\n",
    "# توابع کمکی\n",
    "def sigmoid(z):\n",
    "    \"\"\"تابع فعال‌سازی سیگموئید\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"مشتق تابع سیگموئید\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7573a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n",
      "a.shape: (10, 1)\n",
      "w.shape: (5, 10)\n",
      "output.shape: (5, 1)\n",
      "a.shape: (5, 1)\n",
      "w.shape: (1, 5)\n",
      "output.shape: (1, 1)\n",
      "a.shape: (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.87953963]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Network([10,5,1])\n",
    "input = np.array( [1,1,1,1,1,2,2,2,2,2] , ndmin=2 ).T\n",
    "print(input)\n",
    "a.feedforward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fb632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
